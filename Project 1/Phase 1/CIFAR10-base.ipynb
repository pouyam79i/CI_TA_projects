{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Required Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only local run: install required libs (recommended python version 3.10)\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install torch torchvision torchaudio tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Functions\n",
    "import torch.optim as Optimizers\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Device\n",
    "You can use GPU instead of CPU for faster calculation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download CIFAR-10 Dataset and Transform to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ToTensor()\n",
    "\n",
    "\"Set download=True to download dataset online\"\n",
    "data_path = './data_cifar/'\n",
    "cifar10_train = CIFAR10(data_path, train=True, download=True, transform=transform)\n",
    "cifar10_test = CIFAR10(data_path, train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Brief View on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of training and test sets\n",
    "print(\"Training: \", len(cifar10_train))\n",
    "print(\"Testing: \", len(cifar10_test))\n",
    "\n",
    "# type of train and test: it is a collection of tuple(tensor, label)\n",
    "print(type(cifar10_train[0]))\n",
    "\n",
    "# label, as you know, is the class of image\n",
    "# tensor contains image data (You will learn more about Tensor later)\n",
    "image, label = cifar10_train[0]\n",
    "print(type(image))\n",
    "\n",
    "# lets check the dimension - it is a 32x32 RGB image\n",
    "print(image.shape)\n",
    "\n",
    "# lets see what classes we have\n",
    "classes = cifar10_train.classes\n",
    "print(classes)\n",
    "print(label)\n",
    "print(classes[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Batch Size\n",
    "It is important to understand that to build the Neural Network we will work with a large number of parameters. For this reason, it makes sense to load training data in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"TODO: set a proper batch size\"\n",
    "train_loader = DataLoader(cifar10_train, batch_size=..., shuffle=True)\n",
    "test_loader = DataLoader(cifar10_test, batch_size=..., shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model\n",
    "Here you need to define your model architecture, use your knowledge of ANN to design one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \"TODO: define model layers\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"TODO: define model forward path\"\n",
    "        return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"TODO: set a proper loss function\"\n",
    "criterion = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose an Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"TODO: set a proper optimizer\"\n",
    "optimizer = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model\n",
    "After configuring all required parameters, it is time to train your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"TODO: set an optimal epoch\"\n",
    "EPOCHS = ...\n",
    "\n",
    "\" you don't need to change the rest of this code\"\n",
    "\n",
    "train_correct  = []\n",
    "test_correct = []\n",
    "\n",
    "best_train_acc = 0\n",
    "best_test_acc = 0\n",
    "\n",
    "for e in tqdm(range(EPOCHS)):\n",
    "\n",
    "  trn_corr = 0\n",
    "  tst_corr = 0\n",
    "\n",
    "  # training\n",
    "  model.train()\n",
    "  for X_train, y_train in train_loader:\n",
    "\n",
    "    X_train_dev = torch.autograd.Variable(X_train).to(device)\n",
    "    y_train_dev = torch.autograd.Variable(y_train).to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_pred_dev = model(X_train_dev)\n",
    "    loss = criterion(y_pred_dev, y_train_dev)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    predicted = torch.argmax(y_pred_dev, 1)\n",
    "    trn_corr += torch.sum(predicted == y_train_dev)\n",
    "\n",
    "  acc = (trn_corr/len(cifar10_train)).item()\n",
    "  best_train_acc = acc if(best_train_acc < acc) else best_train_acc\n",
    "  train_correct.append(acc)\n",
    "\n",
    "  # testing\n",
    "  model.eval()\n",
    "  for X_test, y_test in test_loader:\n",
    "\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "\n",
    "    predicted = model(X_test)\n",
    "    predicted = torch.argmax(predicted, 1)\n",
    "    tst_corr += torch.sum(predicted == y_test)\n",
    "\n",
    "  acc = (tst_corr/len(cifar10_test)).item()\n",
    "  best_test_acc = acc if(best_test_acc < acc) else best_test_acc\n",
    "  test_correct.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Here you can see your model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_correct, label='train accuracy')\n",
    "plt.plot(test_correct, label = 'test accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show();\n",
    "\n",
    "print(\"\\nOn train - best accuracy: {:.2f}, final accuracy: {:.2f}\".format(best_train_acc, train_correct[-1]))\n",
    "print(\"On test - best accuracy: {:.2f}, final accuracy: {:.2f}\".format(best_test_acc, test_correct[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
